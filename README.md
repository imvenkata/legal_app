# Legal AI Assistant

A full-stack application using AI for legal document upload, analysis, research, contract generation, and vector-based semantic search with RAG capabilities.

## Features

-   **Document Management:** Securely upload and manage legal documents (PDF, DOCX, TXT).
-   **AI Analysis:** Leverage LLMs for document summarization, key point extraction, etc. (Original Feature)
-   **Vector Search:** Index documents into a vector database (Qdrant) for efficient semantic search.
-   **Retrieval-Augmented Generation (RAG):** Ask questions about your documents and receive answers generated by an LLM (e.g., OpenAI GPT) based on relevant retrieved context, complete with source citations.
-   **Contract Generation:** AI-assisted contract drafting and management. (Original Feature)
-   **User Authentication:** Secure user login and registration using JWT. (Original Feature)
-   **Modern UI:** Responsive user interface built with React and Material UI.

## Tech Stack

### Backend (`backend/` - Main Service - Assumed)
-   FastAPI (Python web framework)
-   MongoDB (Database - Assumed from original README)
-   JWT Authentication
-   OpenAI / Google AI integration (for features other than search)
-   `uv` for package management

### Backend (`legal_search_service/` - Search Service)
-   FastAPI (Python web framework)
-   **Qdrant** (Vector Database)
-   **Sentence Transformers** (for text embeddings)
-   **LlamaParse** (for document parsing)
-   **OpenAI / DeepSeek** (Configurable, for RAG answer generation)
-   `uv` / `pip` for package management

### Frontend (`frontend/`)
-   React
-   Material-UI
-   Redux Toolkit
-   Axios for API calls
-   React Router for navigation
-   React Dropzone (for file uploads)

## Prerequisites

-   **Python:** 3.8+ (as per original README)
-   **Node.js:** 14+ (as per original README)
-   **npm:** (comes with Node.js)
-   **Docker:** Required for running Qdrant locally.
-   **uv:** Python package installer (see installation below).
-   **Git:** For cloning the repository.
-   **API Keys:**
    -   **OpenAI API Key:** Required for the RAG search functionality in `legal_search_service`.
    -   **DeepSeek API Key:** Required if `LLM_PROVIDER` is set to `deepseek`.
    -   *Potentially* Google AI API Key / other keys if used by the main `backend` service.
    -   *Optional* LlamaParse API Key for advanced document parsing features.
-   **MongoDB:** Needs to be running if used by the main `backend` service.

## Setup

### 1. Clone the Repository
```bash
git clone <your-repository-url>
cd <your-repository-directory>
```

### 2. Install uv (Python Package Manager)

Follow the instructions from the original README:
```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Make sure it's in your PATH
# For bash/zsh, add to .bashrc or .zshrc:
# export PATH="$HOME/.local/bin:$PATH"
# Restart your shell after adding to PATH
```

### 3. Backend Setup

This project uses two backend services. You need to set up both.

**a) Main Backend Service (`backend/`)** (Based on original README structure)

*   Navigate to the project root.
*   Create/activate a virtual environment using `uv`:
    ```bash
    uv venv venv_backend  # Create a separate venv for the main backend
    source venv_backend/bin/activate # On Windows: venv_backend\Scripts\activate
    ```
*   Install dependencies:
    ```bash
    # Assuming requirements are in backend/requirements.txt as per original README
    uv pip sync backend/requirements.txt
    ```
*   Deactivate this environment for now (optional, just to avoid confusion):
    ```bash
    deactivate
    ```

**b) Search Backend Service (`legal_search_service/`)**

*   Navigate to the project root.
*   Create/activate a *separate* virtual environment using `uv`:
    ```bash
    # Using uv for this service as well
    uv venv venv_search 
    source venv_search/bin/activate # On Windows: venv_search\Scripts\activate
    ```
*   Install dependencies using `uv`:
    ```bash
    uv pip sync legal_search_service/requirements.txt
    ```
*   Deactivate this environment for now:
    ```bash
    deactivate
    ```

### 4. Frontend Setup (`frontend/`)

*   Install dependencies:
    ```bash
    cd frontend
    npm install
    cd .. # Go back to project root
    ```

### 5. Configuration (.env Files)

Set up environment variables for both backend services and the frontend.

**a) Main Backend (`.env` in root or `backend/`)**

*   Copy the example file if it exists: `cp .env.example .env` (adjust path if needed).
*   Edit the `.env` file with your specific configuration for the main backend (MongoDB connection, JWT secret, OpenAI/Google keys if used here, etc.).

**b) Search Backend (`legal_search_service/.env`)**

*   Create a file named `.env` inside the `legal_search_service` directory (`legal_search_service/.env`).
*   Add the following, **replacing placeholders**:

    ```dotenv
    # --- Qdrant Configuration ---
    QDRANT_URL=http://localhost:6333
    QDRANT_API_KEY=
    COLLECTION_NAME=legal_documents

    # --- Embedding Model ---
    EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

    # --- LlamaParse (Optional) ---
    LLAMA_CLOUD_API_KEY=

    # --- OpenAI LLM --- (Required if LLM_PROVIDER=openai)
    OPENAI_API_KEY=your_openai_api_key_here 
    OPENAI_MODEL_NAME=gpt-4o
    
    # --- DeepSeek LLM --- (Required if LLM_PROVIDER=deepseek)
    DEEPSEEK_API_KEY=your_deepseek_api_key_here
    DEEPSEEK_MODEL_NAME=deepseek-chat # Or deepseek-coder
    DEEPSEEK_BASE_URL=https://api.deepseek.com/v1 # Verify this URL

    # --- LLM Selection ---
    LLM_PROVIDER=deepseek # Options: "openai", "deepseek"

    # --- Data Path ---
    DATA_PATH=./data
    ```

**c) Frontend (`frontend/.env`)**

*   Copy the example file if it exists: `cd frontend; cp .env.example .env; cd ..`.
*   Edit `frontend/.env` and ensure these variables are present and correct:

    ```dotenv
    REACT_APP_SEARCH_API_URL=http://localhost:8001/api/v1 # URL for the Search Service
    REACT_APP_API_URL=http://localhost:8000              # URL for the Main Backend (adjust if needed)
    ```

## Running the Application

Start the services in separate terminals from the **project root directory**.

1.  **Start Qdrant (Vector Database via Docker):**
    *   *(Terminal 1)*
    *   Qdrant is used as the vector database. The easiest way to run it locally is using Docker.
    *   Run the official Qdrant image, mapping the necessary ports (6333 for HTTP, 6334 for gRPC) and mounting a volume for data persistence:
    ```bash
    docker run -p 6333:6333 -p 6334:6334 \
           -v "$(pwd)/qdrant_data:/qdrant/storage:z" \
           qdrant/qdrant
    ```
    *   **Note:** The `-v "$(pwd)/qdrant_data:/qdrant/storage:z"` part mounts a directory named `qdrant_data` from your current project root into the container. This ensures your indexed data persists even if you stop and restart the container. Create this `qdrant_data` directory if it doesn't exist. `$(pwd)` works on Linux/macOS/Git Bash; adjust the path before `/qdrant_data` if needed for other shells.
    *   Leave this terminal running. Qdrant will be accessible at `http://localhost:6333`.


    Qdrant is now accessible:

    REST API: localhost:6333
    Web UI: localhost:6333/dashboard
    GRPC API: localhost:6334



2.  **Start Main Backend Service:** (If applicable)
    *   *(Terminal 2)*
    *   Activate the main backend virtual environment: `source venv_backend/bin/activate`
    *   Run the server (adjust `app:app` if your entry point differs):
        ```bash
        uvicorn backend.app:app --reload --port 8000 # Assuming entry point is backend/app.py
        ```
    *   Leave this running.

3.  **Start Search Backend Service:**
    *   *(Terminal 3)*
    *   Activate the search service virtual environment: `source venv_search/bin/activate`
    *   Run the server:
        ```bash
        uvicorn legal_search_service.api.main:app --reload --port 8001
        ```
    *   Leave this running.

4.  **Start Frontend:**
    *   *(Terminal 4)*
    *   Navigate to the frontend directory: `cd frontend`
    *   Start the React app:
        ```bash
        npm start
        ```
    *   This should open `http://localhost:3000` (or similar) in your browser.

## Using the Application

1.  **Upload Documents:**
    *   Navigate to the `/documents` page.
    *   Use the "Upload Documents for Search Indexing" section (drag & drop or click).
    *   Select files (PDF, DOCX, TXT) and click "Upload".
    *   Ingestion (parsing, embedding, indexing) will start in the background.

2.  **Ask Questions (RAG Search):**
    *   Navigate to the `/research` page.
    *   Use the "Ask a Legal Question (RAG)" input.
    *   Type your question related to the uploaded documents and click "Ask".
    *   The app retrieves relevant context and uses the configured LLM to generate an answer with citations.

## Development

*(Keep relevant sections from original README regarding uv usage for main backend, testing, code style, etc.)*

### Package Management with uv (Main Backend)
```bash
# Activate main backend venv first
# uv pip add package_name
# uv pip sync backend/requirements.txt
# uv pip freeze > backend/requirements.txt
```

### Running Tests
```bash
# Activate relevant venv first
# cd backend; pytest
# cd frontend; npm test
```

### Code Style
```bash
# Activate relevant venv first
# cd backend; black .; isort .; flake8
# cd frontend; npm run lint
```

## Deployment

*(Keep relevant sections from original README, potentially needing updates for deploying multiple backends and Qdrant)*

## Security Considerations

*(Keep relevant sections from original README)*

## Contributing

*(Keep relevant sections from original README)*

## License

*(Keep relevant sections from original README)* 