# Legal AI Assistant

A full-stack application using AI for legal document upload, analysis, research, contract generation, and vector-based semantic search with RAG capabilities.

## Features

-   **Document Management:** Securely upload and manage legal documents (PDF, DOCX, TXT).
-   **AI Analysis:** Leverage LLMs for document summarization, key point extraction, etc. (Original Feature)
-   **Vector Search:** Index documents into a vector database (Qdrant) for efficient semantic search.
-   **Retrieval-Augmented Generation (RAG):** Ask questions about your documents and receive answers generated by an LLM (e.g., OpenAI GPT) based on relevant retrieved context, complete with source citations.
-   **Contract Generation:** AI-assisted contract drafting and management. (Original Feature)
-   **User Authentication:** Secure user login and registration using JWT. (Original Feature)
-   **Modern UI:** Responsive user interface built with React and Material UI.

## Tech Stack

### Backend (`backend/` - Main Service)
-   FastAPI (Python web framework)
-   MongoDB (Database)
-   JWT Authentication
-   OpenAI / Google AI / PaliGemma integration 
-   `uv` for package management

### Backend (`legal_search_service/` - Search Service)
-   FastAPI (Python web framework)
-   **Qdrant** (Vector Database)
-   **Sentence Transformers** (for text embeddings)
-   **LlamaParse** (for document parsing)
-   **OpenAI / DeepSeek** (Configurable, for RAG answer generation)
-   `uv` / `pip` for package management

### Frontend (`frontend/`)
-   React
-   Material-UI
-   Redux Toolkit
-   Axios for API calls
-   React Router for navigation
-   React Dropzone (for file uploads)

## Prerequisites

-   **Python:** 3.8+ 
-   **Node.js:** 14+ 
-   **npm:** (comes with Node.js)
-   **Docker:** Required for running Qdrant locally (optional, see Troubleshooting section for alternatives).
-   **uv:** Python package installer (see installation below).
-   **Git:** For cloning the repository.
-   **API Keys:**
    -   **OpenAI API Key:** Required for the RAG search functionality if using OpenAI.
    -   **DeepSeek API Key:** Required if `LLM_PROVIDER` is set to `deepseek`.
    -   **PaliGemma Model Access:** If using ColPali provider.
    -   *Optional* LlamaParse API Key for advanced document parsing features.
-   **MongoDB:** Needs to be running if used by the main `backend` service.

## Setup

### 1. Clone the Repository
```bash
git clone <your-repository-url>
cd <your-repository-directory>
```

### 2. Install uv (Python Package Manager)

```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Make sure it's in your PATH
# For bash/zsh, add to .bashrc or .zshrc:
# export PATH="$HOME/.local/bin:$PATH"
# Restart your shell after adding to PATH
```

### 3. Backend Setup

This project uses two backend services. You need to set up both.

**a) Main Backend Service (`backend/`)**

*   Navigate to the project root.
*   Create/activate a virtual environment using `uv`:
    ```bash
    uv venv venv  # Creates venv for main backend
    source venv/bin/activate # On Windows: venv\Scripts\activate
    ```
*   Install dependencies:
    ```bash
    uv pip sync backend/requirements.txt
    ```

**b) Search Backend Service (`legal_search_service/`)**

*   Navigate to the project root.
*   Create/activate a *separate* virtual environment using `uv`:
    ```bash
    uv venv venv_search 
    source venv_search/bin/activate # On Windows: venv_search\Scripts\activate
    ```
*   Install dependencies using `uv`:
    ```bash
    uv pip sync legal_search_service/requirements.txt
    ```

### 4. Frontend Setup (`frontend/`)

*   Install dependencies:
    ```bash
    cd frontend
    npm install
    cd .. # Go back to project root
    ```

### 5. Configuration (.env Files)

Set up environment variables for both backend services and the frontend.

**a) Main Backend (`.env` in `backend/`)**

*   Copy the example file if it exists: `cp backend/.env.example backend/.env` (adjust path if needed).
*   Edit the `.env` file with your specific configuration.

**b) Search Backend (`legal_search_service/.env`)**

*   Create or edit the file named `.env` inside the `legal_search_service` directory.
*   Add the following configuration, replacing placeholders with your actual values:

    ```dotenv
    # --- Qdrant Configuration ---
    QDRANT_URL=http://localhost:6333
    QDRANT_API_KEY=
    COLLECTION_NAME=legal_documents

    # --- Embedding Model ---
    EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

    # --- LlamaParse (Optional) ---
    LLAMA_CLOUD_API_KEY=your_llama_parse_key_here

    # --- OpenAI LLM --- (Required if LLM_PROVIDER=openai)
    OPENAI_API_KEY=your_openai_api_key_here 
    OPENAI_MODEL_NAME=gpt-4o
    
    # --- DeepSeek LLM --- (Required if LLM_PROVIDER=deepseek)
    DEEPSEEK_API_KEY=your_deepseek_api_key_here
    DEEPSEEK_MODEL_NAME=deepseek-chat
    DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

    # --- LLM Selection ---
    LLM_PROVIDER=deepseek # Options: "openai", "deepseek"

    # --- Data Path ---
    DATA_PATH=./data
    ```

**c) Frontend (`frontend/.env`)**

*   Edit `frontend/.env` and ensure these variables are present and correct:

    ```dotenv
    REACT_APP_SEARCH_API_URL=http://localhost:8001/api/v1 # URL for the Search Service
    REACT_APP_API_URL=http://localhost:8000              # URL for the Main Backend
    ```

## Running the Application

Start the services in separate terminals from the **project root directory**.

1.  **Start Qdrant (Vector Database via Docker):**
    *   *(Terminal 1)*
    *   Ensure Docker is running on your system.
    *   Run the official Qdrant image:
    ```bash
    mkdir -p qdrant_data
    docker run -p 6333:6333 -p 6334:6334 \
           -v "$(pwd)/qdrant_data:/qdrant/storage:z" \
           qdrant/qdrant
    ```
    *   Leave this terminal running. Qdrant will be accessible at `http://localhost:6333`.

2.  **Start Main Backend Service:**
    *   *(Terminal 2)*
    *   Activate the main backend virtual environment: `source venv/bin/activate`
    *   Run the backend service:
        ```bash
        cd backend
        python app.py
        ```
    *   The service will be available at `http://localhost:8000`.

3.  **Start Search Backend Service:**
    *   *(Terminal 3)*
    *   Activate the search service virtual environment: `source venv_search/bin/activate`
    *   Run the server with the correct PYTHONPATH:
        ```bash
        cd legal_search_service
        PYTHONPATH=. python -m uvicorn api.main:app --host 0.0.0.0 --port 8001
        ```
    *   The service will be available at `http://localhost:8001`.

4.  **Start Frontend:**
    *   *(Terminal 4)*
    *   Navigate to the frontend directory: `cd frontend`
    *   Start the React app:
        ```bash
        npm start
        ```
    *   This should open `http://localhost:3001` in your browser (note: port may vary if 3001 is already in use).

## Using the Application

1.  **Upload Documents:**
    *   Navigate to the `/documents` page.
    *   Use the "Upload Documents for Search Indexing" section (drag & drop or click).
    *   Select files (PDF, DOCX, TXT) and click "Upload".
    *   Ingestion (parsing, embedding, indexing) will start in the background.

2.  **Ask Questions (RAG Search):**
    *   Navigate to the `/research` page.
    *   Use the "Ask a Legal Question (RAG)" input.
    *   Type your question related to the uploaded documents and click "Ask".
    *   The app retrieves relevant context and uses the configured LLM to generate an answer with citations.

## Troubleshooting

### Docker/Qdrant Issues

If you encounter issues with Docker or running Qdrant:

1. Make sure Docker Desktop is installed and running on your system.
2. If Docker cannot be used, you can try:
   - Using a cloud-hosted Qdrant instance (update the QDRANT_URL in .env)
   - Using a different vector database like Milvus or Chroma (requires code modifications)
   - Running Qdrant without Docker (see Qdrant documentation for standalone installation)

### Search Service Import Issues

If you encounter the error `ModuleNotFoundError: No module named 'legal_search_service'`:

1. Always run the search service with the PYTHONPATH set correctly:
   ```bash
   cd legal_search_service
   PYTHONPATH=. python -m uvicorn api.main:app --host 0.0.0.0 --port 8001
   ```

2. Alternatively, you can modify the import statements in the code to use relative imports.

### Frontend Port Issues

If port 3000 is already in use, the application will ask to use a different port (usually 3001). Update your frontend configuration or browser bookmarks accordingly.

## Development

### Package Management with uv (Main Backend)
```bash
# Activate main backend venv first
# uv pip add package_name
# uv pip sync backend/requirements.txt
# uv pip freeze > backend/requirements.txt
```

### Running Tests
```bash
# Activate relevant venv first
# cd backend; pytest
# cd frontend; npm test
```

### Code Style
```bash
# Activate relevant venv first
# cd backend; black .; isort .; flake8
# cd frontend; npm run lint
```

## Deployment

*(Keep relevant sections from original README, potentially needing updates for deploying multiple backends and Qdrant)*

## Security Considerations

*(Keep relevant sections from original README)*

## Contributing

*(Keep relevant sections from original README)*

## License

*(Keep relevant sections from original README)* 